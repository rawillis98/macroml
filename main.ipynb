{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import time #helper libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import talib\n",
    "np.set_printoptions(precision = 2)\n",
    "log(\"Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log.txt\", \"w+\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def log(msg):\n",
    "    with open(\"log.txt\", 'a') as f:\n",
    "        f.write(msg + '\\n')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa2653e5b6ae087226044b02901d70f7401ddf05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days In Between Training: 140\n",
      "Previous Days of Returns Included as Features: 2\n",
      "Validation Split: 0.26\n",
      "Testing...\n",
      "0 0.5928571428571429\n",
      "140 0.6142857142857143\n",
      "280 0.6071428571428571\n",
      "420 0.5964285714285714\n",
      "Fitness : 0.5964285714285714\n",
      "Days In Between Training: 146\n",
      "Previous Days of Returns Included as Features: 11\n",
      "Validation Split: 0.1\n",
      "Testing...\n",
      "0 0.5342465753424658\n",
      "146 0.571917808219178\n",
      "292 0.5662100456621004\n",
      "438 0.5753424657534246\n",
      "Fitness : 0.5753424657534246\n",
      "Days In Between Training: 181\n",
      "Previous Days of Returns Included as Features: 39\n",
      "Validation Split: 0.23\n",
      "Testing...\n",
      "0 0.44751381215469616\n",
      "181 0.46685082872928174\n",
      "362 0.47882136279926335\n",
      "Fitness : 0.47882136279926335\n",
      "Days In Between Training: 48\n",
      "Previous Days of Returns Included as Features: 43\n",
      "Validation Split: 0.24\n",
      "Testing...\n",
      "0 0.5625\n",
      "48 0.5729166666666666\n",
      "96 0.5763888888888888\n",
      "144 0.5729166666666666\n",
      "192 0.5458333333333333\n",
      "240 0.5347222222222222\n",
      "288 0.5238095238095238\n",
      "336 0.5104166666666666\n",
      "384 0.5069444444444444\n",
      "432 0.5083333333333333\n",
      "480 0.5018939393939394\n",
      "Fitness : 0.5018939393939394\n",
      "Days In Between Training: 202\n",
      "Previous Days of Returns Included as Features: 7\n",
      "Validation Split: 0.14\n",
      "Testing...\n",
      "0 0.5841584158415841\n",
      "202 0.5915841584158416\n",
      "404 0.5874587458745875\n",
      "Fitness : 0.5874587458745875\n",
      "Days In Between Training: 206\n",
      "Previous Days of Returns Included as Features: 22\n",
      "Validation Split: 0.03\n",
      "Testing...\n"
     ]
    }
   ],
   "source": [
    "class Genome:\n",
    "    #params define the range of allowed values for hyperparameters\n",
    "    #if params for a hyperparameter are [a, b, c], the hyperparameter mutates as c*(np.random.randint(a)+b)\n",
    "    params = {}\n",
    "    params[\"number_per_model\"] = [255, 1, 1]\n",
    "    params[\"LOOK_BACK\"] = [50, 1, 1]\n",
    "    params[\"VALIDATION_SPLIT\"] = [30, 0, 0.01]\n",
    "    \n",
    "    def __init__(self, genes_dict):\n",
    "        if genes_dict == 'random':\n",
    "            self.random()\n",
    "        else:\n",
    "            self.genes_dict = genes_dict\n",
    "        return\n",
    "    \n",
    "    def random(self):\n",
    "        self.genes_dict = {}\n",
    "        for param in Genome.params.keys():\n",
    "            a = Genome.params[param][0]\n",
    "            b = Genome.params[param][1]\n",
    "            c = Genome.params[param][2]\n",
    "            self.genes_dict[param] = c*(np.random.randint(a) + b)\n",
    "        return\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.genes_dict[key]\n",
    "    \n",
    "    def mutate(self):\n",
    "        for key in self.genes_dict.keys():\n",
    "            if np.random.randint(len(self.genes_dict.keys())) == 0:\n",
    "                a = Genome.params[key][0]\n",
    "                b = Genome.params[key][1]\n",
    "                c = Genome.params[key][2]\n",
    "                self.genes_dict[key] = c*(np.random.randint(a)+b)\n",
    "        return\n",
    "\n",
    "def cross_over(parent_a, parent_b):\n",
    "    offspring = {}\n",
    "    for key in parent_a.genes.genes_dict.keys():\n",
    "        a = np.random.randint(2)\n",
    "        if a == 1:\n",
    "            offspring[key] = parent_a.genes[key]\n",
    "        elif a == 0:\n",
    "            offspring[key] = parent_b.genes[key]\n",
    "        else:\n",
    "            raise(\"Invalid\")\n",
    "    offspring = Genome(offspring)\n",
    "    offspring.mutate()\n",
    "    return Individual(offspring)\n",
    "        \n",
    "        \n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, x):\n",
    "        if x == 'random':\n",
    "            self.genes = Genome('random')\n",
    "        else:\n",
    "            self.genes = x\n",
    "        \n",
    "        self.number_per_model = self.genes[\"number_per_model\"]\n",
    "        self.LOOK_BACK = self.genes[\"LOOK_BACK\"]\n",
    "        self.VALIDATION_SPLIT = self.genes[\"VALIDATION_SPLIT\"]\n",
    "        \n",
    "        log(\"Days In Between Training: \" + str(self.number_per_model))\n",
    "        log(\"Previous Days of Returns Included as Features: \" + str(self.LOOK_BACK))\n",
    "        log(\"Validation Split: \" + str(self.VALIDATION_SPLIT))\n",
    "        return\n",
    "    \n",
    "    def printGenes(self):\n",
    "        log(self.genes.genes_dict)\n",
    "        return\n",
    "    def train(self, verbose = False):\n",
    "        accuracy = []\n",
    "        if verbose:\n",
    "            log(\"Testing...\")\n",
    "        for day in range(0, 500, self.number_per_model):\n",
    "            prices = pd.read_csv('./prices-split-adjusted.csv') #get data\n",
    "            stock = prices.loc[prices['symbol'] == 'AAPL'].copy() #get only GOOG prices\n",
    "            stock[\"y\"] = (stock.close - stock.close.shift(1))/stock.close.shift(1) #create returns (called y since that's what we're trying to predict)\n",
    "            #Add features\n",
    "            for i in range(1, self.LOOK_BACK+1):\n",
    "                #Add column for returns of n days ago (e.g. yesterday's returns, the returns of the day before yesterday...)\n",
    "                stock[str(i) + \" Days Ago\"] = stock[\"y\"].shift(i)\n",
    "            stock[\"RSI_14\"] = talib.RSI(stock.close, 14)\n",
    "            technical_indicators = [\"RSI_14\"]\n",
    "            stock = stock[['y'] + [str(i) + \" Days Ago\" for i in range(1, self.LOOK_BACK + 1)] + technical_indicators].copy().dropna() #drop the other columns\n",
    "\n",
    "            #Scale and separate test and train data\n",
    "            train_length = 1000\n",
    "            train_start = day\n",
    "            train_stop = train_start+train_length\n",
    "            train = stock.loc[stock.index[0:train_stop]]\n",
    "            zero = 'a'\n",
    "            for col in stock.columns: \n",
    "                scaler = MinMaxScaler(feature_range=(0,1))\n",
    "                scaler.fit(train[[col]]) #!!!!!!!!!!!!!!!! ONLY FIT SCALER ON TRAINING DATA, FITTING ON TEST DATA AS WELL IS CHEATING !!!!!!!!!!!!\n",
    "                stock[col] = scaler.transform(stock[[col]]) #apply scaler to all data \n",
    "                if col == 'y':\n",
    "                    zero = scaler.transform(np.reshape(np.array(0), (1, 1)))[0][0]\n",
    "            #Actually separate test data\n",
    "            stock = np.array(stock.values)\n",
    "            x_train = stock[train_start:train_stop, 1:]\n",
    "            test_stop = train_stop + self.number_per_model\n",
    "            x_test = np.array(stock[train_stop:test_stop, 1:])\n",
    "            y_train = stock[train_start:train_stop, 0]\n",
    "            y_test = np.array(stock[train_stop:test_stop, 0])\n",
    "\n",
    "            x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "            x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "\n",
    "            #Define model architecture (copied from someone else's model, will optimize with a genetic algorithm later)\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(input_shape=(1, x_train.shape[2]),units = 50,return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(100,return_sequences=False))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=1))\n",
    "            model.add(Activation('linear'))\n",
    "\n",
    "            #Compile, fit on training data, and evaluate on test data\n",
    "            model.compile(loss='mse', optimizer='rmsprop')\n",
    "            model.fit(x_train, y_train, batch_size = 128, epochs=10, validation_split = self.VALIDATION_SPLIT, verbose = 0)\n",
    "            #model.evaluate(x_test, y_test, verbose = 0)\n",
    "            y_predict = model.predict(x_test)\n",
    "            for i in range(len(y_test)):\n",
    "                correct = int(not(bool(y_predict[i][0] > zero) ^ bool(y_test[i] > zero)))\n",
    "                accuracy.append(correct)\n",
    "            if verbose:\n",
    "                log(str(day) + \" \" + str(sum(accuracy)/len(accuracy)))\n",
    "            self.fitness = sum(accuracy)/len(accuracy)\n",
    "        return \n",
    "    \n",
    "class GeneticAlgorithm:\n",
    "    PROPORTION_TO_KILL = 0.5\n",
    "    CARRYING_CAPACITY = 20\n",
    "    CHILDREN_PER_COUPLE = 2\n",
    "    STARTING_POPULATION = 10\n",
    "    def __init__(self):\n",
    "        #create population\n",
    "        self.population = []\n",
    "        for i in range(GeneticAlgorithm.STARTING_POPULATION):\n",
    "            model = Individual('random')\n",
    "            model.train(verbose = True)\n",
    "            log(\"Fitness : \" + str(model.fitness))\n",
    "            self.population.append(model)\n",
    "        return\n",
    "    \n",
    "    def kill(self):\n",
    "        log(\"Killing least fit members\")\n",
    "        self.population.sort(key = lambda x: x.fitness)\n",
    "        cutoff = math.floor(len(self.population * GeneticAlgorithm.PROPORTION_TO_KILL))\n",
    "        self.population = self.population[cutoff:]\n",
    "    \n",
    "    def chooseParents(self):\n",
    "        #random\n",
    "        return self.population[np.random.randint(len(self.population))], self.population[np.random.randint(len(self.population))]\n",
    "    \n",
    "    def mate(self):\n",
    "        log(\"Mating remai\")\n",
    "        size_before_mating = len(self.population)\n",
    "        while(len(self.population) < GeneticAlgorithm.CARRYING_CAPACITY and len(self.population) < (size_before_mating/GeneticAlgorithm.PROPORTION_TO_KILL + 2)):\n",
    "            parent_a, parent_b = self.chooseParents()\n",
    "            for i in range(GeneticAlgorithm.CHILDREN_PER_COUPLE):\n",
    "                offspring = cross_over(parent_a, parent_b)\n",
    "                offspring.train()\n",
    "                self.population.append(offspring)\n",
    "                \n",
    "    def getPopulationFitness(self):\n",
    "        return np.mean([member.fitness for member in self.population])\n",
    "    \n",
    "    def train(self, generations):\n",
    "        for gen in generations:\n",
    "            log(\"Generation: \" + str(gen) +  \" Population Fitness: \" + str(self.getPopulationFitness()))\n",
    "            self.kill()\n",
    "            self.mate()\n",
    "algo = GeneticAlgorithm()\n",
    "algo.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
