{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from subprocess import check_output\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nfrom sklearn.model_selection import  train_test_split\nimport time #helper libraries\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nfrom numpy import newaxis\nimport math\nimport talib",
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'talib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-327-43b3affcd4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtalib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'talib'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08f7c44b505a730404f49a42463d12502bb26989"
      },
      "cell_type": "code",
      "source": "fundamentals = pd.read_csv('../input/fundamentals.csv')\nstock_fundamentals = fundamentals.loc[fundamentals['Ticker Symbol'] == 'AAPL'].copy()\nstock_fundamentals.resample('D')\nstock_fundamentals.head()",
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-325-23ff3a1c86d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfundamentals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/fundamentals.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstock_fundamentals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfundamentals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfundamentals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticker Symbol'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstock_fundamentals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstock_fundamentals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(self, rule, how, axis, fill_method, closed, label, convention, kind, loffset, limit, base, on, level)\u001b[0m\n\u001b[1;32m   7108\u001b[0m                      \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m                      \u001b[0mconvention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7110\u001b[0;31m                      base=base, key=on, level=level)\n\u001b[0m\u001b[1;32m   7111\u001b[0m         return _maybe_process_deprecations(r,\n\u001b[1;32m   7112\u001b[0m                                            \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;34m\"\"\" create a TimeGrouper and return our resampler \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         raise TypeError(\"Only valid with DatetimeIndex, \"\n\u001b[1;32m   1275\u001b[0m                         \u001b[0;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                         \"but got an instance of %r\" % type(ax).__name__)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa2653e5b6ae087226044b02901d70f7401ddf05"
      },
      "cell_type": "code",
      "source": "prices = pd.read_csv('../input/prices-split-adjusted.csv') #get data\nstock = prices.loc[prices['symbol'] == 'AAPL'].copy() #get only GOOG prices\nstock[\"y\"] = (stock.close - stock.close.shift(1))/stock.close.shift(1) #create returns (called y since that's what we're trying to predict)\n\n#Add features\nfor i in range(1, LOOK_BACK+1):\n    #Add column for returns of n days ago (e.g. yesterday's returns, the returns of the day before yesterday...)\n    stock[str(i) + \" Days Ago\"] = stock[\"y\"].shift(i)\nstock = stock[['y'] + [str(i) + \" Days Ago\" for i in range(1, LOOK_BACK + 1)]].copy().dropna() #drop the other columns\n\n#Scale and separate test and train data\nTEST_SIZE = 0.33\ntrain_stop = math.floor((1-TEST_SIZE)*len(stock.index)) #index of where test data starts and training data stops\ntrain = stock.loc[stock.index[0:train_stop]]\nfor col in stock.columns: \n    scaler = MinMaxScaler(feature_range=(0,1))\n    scaler.fit(train[[col]]) #!!!!!!!!!!!!!!!! ONLY FIT SCALER ON TRAINING DATA, FITTING ON TEST DATA AS WELL IS CHEATING !!!!!!!!!!!!\n    stock[col] = scaler.transform(stock[[col]]) #apply scaler to all data \n\n#Actually separate test data\nstock = np.array(stock.values)\nx_train = stock[:train_stop, 1:]\nx_test = stock[train_stop:, 1:]\ny_train = stock[:train_stop, 0]\ny_test = stock[train_stop:, 0]\nx_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n\n#Define model architecture (copied from someone else's model, will optimize with a genetic algorithm later)\nmodel = Sequential()\nmodel.add(LSTM(input_shape=(1, x_train.shape[2]),units = 50,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100,return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=1))\nmodel.add(Activation('linear'))\n\n#Compile, fit on training data, and evaluate on test data\nmodel.compile(loss='mse', optimizer='rmsprop')\nmodel.fit(x_train, y_train, batch_size = 128, epochs=10, validation_split = 0.05, verbose = 0)\nmodel.evaluate(x_test, y_test, verbose = 0)\ny_predict = model.predict(x_test)\nreturns = []\nfor i in range(len(x_test) - 1):\n    if y_predict[i][0] > x_test[i][0][-1]:\n        returns.append((y_test[i]-x_test[i][0][-1])/x_test[i][0][-1])\n    else:\n        returns.append(0)\nsharpe = np.mean(returns)/np.std(returns)\nprint(\"Sharpe Ratio: \", sharpe)",
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": "            date symbol       open    ...          high       volume         y\n254   2010-01-04   AAPL  30.490000    ...     30.642857  123432400.0       NaN\n721   2010-01-05   AAPL  30.657143    ...     30.798571  150476200.0  0.001729\n1189  2010-01-06   AAPL  30.625713    ...     30.747143  138040000.0 -0.015906\n1657  2010-01-07   AAPL  30.250000    ...     30.285715  119282800.0 -0.001849\n2125  2010-01-08   AAPL  30.042856    ...     30.285715  111902700.0  0.006648\n\n[5 rows x 8 columns]\n              date symbol    ...         volume         y\n848767  2016-12-23   AAPL    ...     14249500.0  0.001978\n849267  2016-12-27   AAPL    ...     18296900.0  0.006351\n849767  2016-12-28   AAPL    ...     20905900.0 -0.004264\n850267  2016-12-29   AAPL    ...     15039500.0 -0.000257\n850767  2016-12-30   AAPL    ...     30586300.0 -0.007796\n\n[5 rows x 8 columns]\nSharpe Ratio:  0.3493611507277231\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}